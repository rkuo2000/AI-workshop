---
layout: post
title: Retrieval-Augmented Generation
author: [Richard Kuo]
category: [Lecture]
tags: [jekyll, ai]
---

Introduction to Retrieval-Augmented Generation (RAG)

---
## RAG
![](https://blogs.mathworks.com/deep-learning/files/2024/01/rag.png)

---
### Retrieval-Augmented Generation
**Paper:** [Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks](https://arxiv.org/abs/2005.11401)
![](https://eugeneyan.com/assets/rag.jpg)

---
#### [A Guide on 12 Tuning Strategies for Production-Ready RAG Applications](https://towardsdatascience.com/a-guide-on-12-tuning-strategies-for-production-ready-rag-applications-7ca646833439#156e)
![](https://miro.medium.com/v2/resize:fit:720/format:webp/1*tT14GpYfEMSqCjnt2UQOGQ.png)

---
#### [NLP • Retrieval Augmented Generation](https://aman.ai/primers/ai/RAG/)
<p><img width="50%" height="50%" src="https://aman.ai/primers/ai/assets/RAG/4.png"></p>

---
### [Patterns for Building LLM-based Systems & Products](https://eugeneyan.com/writing/llm-patterns/)
<p><img width="50%" height="50%" src="https://eugeneyan.com/assets/llm-patterns-og.png"></p>

---
#### [Fusion-in-Decoder (FiD)](https://arxiv.org/abs/2007.01282)
![](https://eugeneyan.com/assets/fid.jpg)

---
#### [Retrieval-Enhanced Transformer (RETRO)](https://arxiv.org/abs/2112.04426)
![](https://eugeneyan.com/assets/retro.jpg)

---
#### [Internet-augmented LMs](https://arxiv.org/abs/2203.05115)
![](https://eugeneyan.com/assets/internet-llm.jpg)

---
#### [Overview of RAG for CodeT5+](https://arxiv.org/abs/2305.07922)
![](https://eugeneyan.com/assets/codet5.jpg)

---
#### [Hypothetical document embeddings (HyDE)](https://arxiv.org/abs/2212.10496)
![](https://eugeneyan.com/assets/hyde.jpg)

---
### LlamaIndex
**Code:** [https://github.com/run-llama/llama_index](https://github.com/run-llama/llama_index)<br>
**Kaggle:** [https://www.kaggle.com/code/rkuo2000/llm-llamaindex](https://www.kaggle.com/code/rkuo2000/llm-llamaindex)<br>
LlamaIndex (GPT Index) is a data framework for your LLM application.
* Offers data connectors to ingest your existing data sources and data formats (APIs, PDFs, docs, SQL, etc.)
* Provides ways to structure your data (indices, graphs) so that this data can be easily used with LLMs.
* Provides an advanced retrieval/query interface over your data: Feed in any LLM input prompt, get back retrieved context and knowledge-augmented output.
* Allows easy integrations with your outer application framework (e.g. with LangChain, Flask, Docker, ChatGPT, anything else).

---
### LLM Embedder
**Paper:** [Retrieve Anything To Augment Large Language Models](https://arxiv.org/abs/2310.07554)<br>
**Code:** [https://github.com/FlagOpen/FlagEmbedding](https://github.com/FlagOpen/FlagEmbedding)<br>
**Kaggle:** [https://www.kaggle.com/code/rkuo2000/llm-flagembedding](https://www.kaggle.com/code/rkuo2000/llm-flagembedding)<br>
![](https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2a4e4265-7dab-4c5d-b14f-5dfd1b270e75_746x735.png)
![](https://github.com/FlagOpen/FlagEmbedding/raw/master/FlagEmbedding/llm_embedder/imgs/llm-embedder.png)

---
### LM-Cocktail
**Paper:** [LM-Cocktail: Resilient Tuning of Language Models via Model Merging](https://arxiv.org/abs/2311.13534)<br>
**Code:** [https://github.com/FlagOpen/FlagEmbedding/tree/master/LM_Cocktail](https://github.com/FlagOpen/FlagEmbedding/tree/master/LM_Cocktail)<br>

---
### EAGLE-LLM
3X faster for LLM<br>
**Blog:** [EAGLE: Lossless Acceleration of LLM Decoding by Feature Extrapolation](https://sites.google.com/view/eagle-llm)<br>
**Code:** [https://github.com/SafeAILab/EAGLE](https://github.com/SafeAILab/EAGLE)<br>
**Kaggle:** [https://www.kaggle.com/code/rkuo2000/eagle-llm](https://www.kaggle.com/code/rkuo2000/eagle-llm)<br>

---
### Purple Llama CyberSecEval
**Paper:** [Purple Llama CyberSecEval: A Secure Coding Benchmark for Language Models](https://arxiv.org/abs/2312.04724)<br>
**Code:** [CybersecurityBenchmarks](https://github.com/facebookresearch/PurpleLlama/tree/main/CybersecurityBenchmarks)<br>
[meta-llama/LlamaGuard-7b](https://huggingface.co/meta-llama/LlamaGuard-7b)<br>
<table>
<tr><th>           </th><th>Our Test Set (Prompt)</th><th>OpenAI Mod</th><th>ToxicChat</th><th>Our Test Set (Response)</th></tr>
<tr><td>Llama-Guard</td><td>0.945</td><td>0.847</td><td>0.626</td><td>0.953</td></tr>
<tr><td>OpenAI API</td><td>	0.764</td><td>0.856</td><td>0.588</td><td>0.769</td></tr>
<tr><td>Perspective API</td><td>0.728</td><td>0.787</td><td>0.532</td><td>0.699</td></tr>
</table>

---
### GraphRAG
**Paper:** [From Local to Global: A Graph RAG Approach to Query-Focused Summarization](https://arxiv.org/pdf/2404.16130)<br>
**Blog:** [從 RAG 到 GraphRAG：透過圖譜節點關係增強回應精確度](https://idataagent.com/2024/05/06/from-rag-to-graphrag-enhance-response-accuracy-through-graph-node-relationships/)<br>
![](https://miro.medium.com/v2/resize:fit:786/format:webp/0*22VVg9YOaqHLRJ0-)
**Blog:** [GraphRAG: Unlocking LLM discovery on narrative private data](https://www.microsoft.com/en-us/research/blog/graphrag-unlocking-llm-discovery-on-narrative-private-data/)<br>

---
## Applications

### [RAG using LlamaIndex framework to build a simple chatbot, to Q&A a bunch of documents](https://abvijaykumar.medium.com/prompt-engineering-retrieval-augmented-generation-rag-cd63cdc6b00)
![](https://miro.medium.com/v2/resize:fit:720/format:webp/1*PL-HZqYOdczK4PoZjEPlKQ.png)

---
### [RAG with MATLAB](https://blogs.mathworks.com/deep-learning/2024/01/22/large-language-models-with-matlab/)
![](https://blogs.mathworks.com/deep-learning/files/2024/01/LLMs_recording.gif)

---
### [Building RAG-based LLM Applications for Production](https://www.anyscale.com/blog/a-comprehensive-guide-for-building-rag-based-llm-applications-part-1)
**[https://github.com/ray-project/llm-applications/blob/main/notebooks/rag.ipynb](https://github.com/ray-project/llm-applications/blob/main/notebooks/rag.ipynb)**<br>
(1)將外部文件做分塊(chunking)再分詞(tokenize)轉成token<br>
(2)利用嵌入模型，將token做嵌入(embeds)運算，轉成向量，儲存至向量資料庫(Vector Database)並索引(Indexes)<br>
(3)用戶提出問題，向量資料庫將問題字串轉成向量(利用前一個步驟的嵌入模型)，再透過餘弦(Cosine)相似度或歐氏距離演算法來搜尋資料庫裡的近似資料<br>
(4)將用戶的問題、資料庫查詢結果一起放進Prompt(提示)，交由LLM推理出最終答案<br>
以上是基本的RAG流程，利用Langchain或LlamaIndex或Haystack之類的應用程式開發框架，大概用不到一百行的程式碼就能做掉(含LLM的裝載)。<br>

Anyscale剛剛發布的一篇精彩好文，裡頭介紹了很多提升RAG成效的高段技巧，內容包括：<br>
🚀從頭開始建構基於RAG的LLM應用程式。<br>
🚀 在具有不同運算資源的多個工作人員之間擴展主要工作負載（載入、分塊、嵌入、索引、服務等）。<br>
🚀評估應用程式的不同配置，以最佳化每個元件（例如retrieval_score）和整體效能（quality_score）。<br>
🚀 透過開源和閉源LLM實作混合代理路由方法，以建立效能最佳且最具成本效益的應用程式。<br>
🚀以高擴展性與高可用性的方式為應用程式提供服務。<br>
🚀了解微調、提示工程、詞彙搜尋(lexical search)、重新排名、資料飛輪(data flywheel)等方法如何影響應用程式的效能。<br>

<br>
<br>

*This site was last updated {{ site.time | date: "%B %d, %Y" }}.*

